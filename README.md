# MiniMind - Personal AI Assistant Backend

A sophisticated personal AI assistant that can break down complex user requests into subtasks, plan execution steps, and carry them out autonomously using a multi-agent architecture.

## ğŸš€ Features

- **Natural Language Task Processing** - Submit complex requests like "Plan a weekend trip to NYC under $500"
- **Autonomous Task Decomposition** - AI breaks requests into research, planning, execution, etc.
- **Multi-Agent Coordination** - Specialized agents handle different aspects
- **Real-time Progress Tracking** - See the AI "thinking" and executing steps
- **Memory & Context** - Remembers user preferences and past interactions

## ğŸ—ï¸ Architecture

```
User Request â†’ Planner Agent â†’ Task Graph â†’ Specialized Agents â†’ Results
                â†“
Memory Agent (context) â†’ Controller Agent â†’ Real-time Updates
```

### Core Agents

- **Planner Agent** - Decomposes tasks and creates execution plans
- **Research Agent** - Gathers information using web search, APIs
- **Memory Agent** - Manages context and user preferences
- **Executor Agent** - Coordinates actions and tool usage
- **Controller Agent** - Orchestrates the entire workflow

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI with gRPC for inter-service communication
- **AI Framework**: LangChain + LangGraph for agent orchestration
- **Database**: PostgreSQL for persistent memory and task state
- **Message Queue**: Redis + Celery for background tasks
- **Real-time**: WebSocket for live updates

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Python 3.11+
- OpenAI API Key

### 1. Clone and Setup

```bash
git clone <repository-url>
cd minimind
```

### 2. Environment Setup

Create a `.env` file:

```env
OPENAI_API_KEY=your_openai_api_key_here
DATABASE_URL=postgresql://minimind:minimind123@localhost:5432/minimind
REDIS_URL=redis://localhost:6379
```

### 3. Run with Docker

```bash
# Start all services
docker-compose up -d

# Check logs
docker-compose logs -f minimind-backend
```

### 4. Manual Setup (Alternative)

```bash
# Install dependencies
pip install -r requirements.txt

# Start PostgreSQL and Redis
docker-compose up postgres redis -d

# Run migrations
alembic upgrade head

# Start the application
uvicorn app.main:app --reload

# Start Celery worker (in another terminal)
celery -A app.celery_app worker --loglevel=info
```

## ğŸ“¡ API Endpoints

### Core Endpoints

- `POST /tasks` - Create a new task
- `GET /tasks/{task_id}` - Get task status
- `GET /tasks/{task_id}/progress` - Get detailed progress
- `GET /users/{user_id}/tasks` - Get user's tasks

### Demo Endpoints

- `POST /demo/task` - Create a demo task
- `GET /demo/tasks/{task_id}` - Get demo task progress

### WebSocket

- `WS /ws/{task_id}` - Real-time task updates

## ğŸ§ª Testing

### Create a Demo Task

```bash
# Create a demo task
curl -X POST "http://localhost:8000/demo/task"

# Get task progress
curl -X GET "http://localhost:8000/demo/tasks/1"
```

### Manual API Testing

```bash
# Create a user
curl -X POST "http://localhost:8000/users" \
  -H "Content-Type: application/json" \
  -d '{"username": "testuser", "email": "test@example.com"}'

# Create a task
curl -X POST "http://localhost:8000/tasks" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": 1,
    "request": "Plan a weekend trip to NYC under $500",
    "context": {"budget": 500, "destination": "NYC"}
  }'

# Check task status
curl -X GET "http://localhost:8000/tasks/1"
```

## ğŸ”§ Configuration

### Environment Variables

- `OPENAI_API_KEY` - Your OpenAI API key
- `DATABASE_URL` - PostgreSQL connection string
- `REDIS_URL` - Redis connection string
- `DEBUG` - Enable debug mode (default: True)

### Agent Settings

- `MAX_TASK_DURATION` - Maximum task execution time (default: 300s)
- `MAX_SUBTASKS` - Maximum number of subtasks per task (default: 10)

## ğŸ“Š Demo Scenarios

### 1. Trip Planning
- Research flights and hotels
- Create budget breakdown
- Generate itinerary
- Check weather forecast

### 2. Meeting Preparation
- Research participants
- Create agenda
- Prepare materials
- Schedule follow-ups

### 3. Learning Path
- Assess current knowledge
- Create personalized study plan
- Find relevant resources
- Set milestones

### 4. Event Organization
- Research venues
- Create guest list
- Plan logistics
- Send invitations

## ğŸ—ï¸ Project Structure

```
minimind/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/           # AI agents
â”‚   â”‚   â”œâ”€â”€ base.py      # Base agent class
â”‚   â”‚   â”œâ”€â”€ planner.py   # Task decomposition
â”‚   â”‚   â”œâ”€â”€ research.py  # Information gathering
â”‚   â”‚   â”œâ”€â”€ executor.py  # Action execution
â”‚   â”‚   â”œâ”€â”€ memory.py    # Context management
â”‚   â”‚   â””â”€â”€ controller.py # Workflow orchestration
â”‚   â”œâ”€â”€ api.py           # FastAPI routes
â”‚   â”œâ”€â”€ config.py        # Configuration
â”‚   â”œâ”€â”€ database.py      # Database setup
â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py       # Pydantic schemas
â”‚   â”œâ”€â”€ services.py      # Business logic
â”‚   â”œâ”€â”€ tasks.py         # Celery tasks
â”‚   â””â”€â”€ main.py          # Application entry
â”œâ”€â”€ alembic/             # Database migrations
â”œâ”€â”€ docker-compose.yml   # Docker services
â”œâ”€â”€ Dockerfile          # Container setup
â””â”€â”€ requirements.txt    # Dependencies
```

## ğŸ” Monitoring

### Health Check
```bash
curl http://localhost:8000/health
```

### Database Status
```bash
# Connect to PostgreSQL
docker-compose exec postgres psql -U minimind -d minimind

# Check tables
\dt
```

### Celery Status
```bash
# Check Celery workers
docker-compose exec minimind-backend celery -A app.celery_app inspect active
```

## ğŸš€ Deployment

### Production Setup

1. **Environment Variables**
   ```env
   DEBUG=False
   OPENAI_API_KEY=your_production_key
   DATABASE_URL=your_production_db_url
   REDIS_URL=your_production_redis_url
   ```

2. **Database Migration**
   ```bash
   alembic upgrade head
   ```

3. **Start Services**
   ```bash
   docker-compose -f docker-compose.prod.yml up -d
   ```

### Scaling

- **Horizontal Scaling**: Add more Celery workers
- **Database**: Use connection pooling
- **Redis**: Configure clustering for high availability

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License.

## ğŸ†˜ Support

For issues and questions:
- Create an issue on GitHub
- Check the documentation
- Review the API endpoints

---

**MiniMind** - Your Personal AI Assistant ğŸ¤– 